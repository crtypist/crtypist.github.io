
<!doctype html>
<html class="no-js" lang="">

<head>
  <meta charset="utf-8">
  <title>CRTypist: Simulating Touchscreen Typing Behavior via Computational Rationality</title>
  <meta name="description" content="AutoClips: An Automatic Approach to Video Generation from Data Facts">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="manifest" href="site.webmanifest">
  <link rel="apple-touch-icon" href="icon.png">

  <link rel="icon" href="favicon.ico">

  <link rel="stylesheet" href="css/normalize.css">
  <link rel="stylesheet" href="css/main.css">

  <meta name="theme-color" content="#fafafa">
</head>

<body>
  <!--[if IE]>
	<p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <div class="wrapper">
   <header>
     <teaser>
     </teaser>
     <h1>
      <b>CRTypist</b>: 
      <span>Simulating Touchscreen Typing Behavior <br> via Computational Rationality
        </span>
    </h1>
  </header>
  <section>
    <h2>Abstract</h2>
    <p class="abstract">
      Touchscreen typing requires coordinating the fingers and visual attention for button-pressing, proofreading, and error correction. Computational models need to account for the associated fast pace, coordination issues, and closed-loop nature of this control problem, which is further complicated by the immense variety of keyboards and users. The paper introduces CRTypist, which generates human-like typing behavior.  Its key feature is reformulation of the supervisory control problem, with the visual attention and motor system being controlled with reference to a working-memory representation tracking the text typed thus far. Movement policy is assumed to asymptotically approach optimal performance in line with cognitive and design-related bounds. This flexible model works directly from pixels, without requiring hand-crafted feature engineering for keyboards. It produces a good match with human data in terms of movements and performance, covers individual differences, and can generalize to diverse keyboard designs. Though limited to skilled typists' output, the model supplies useful estimates of the typing performance achievable under various conditions.
   </p>
   <img class="teaser" src="img/model.png" />
 </section>
 <!-- <section>
  <img class="teaser" src="img/algorithm.png" />
 </section> -->
 <section>
  <h2>Media</h2>
  <p>coming soon</p>
</section>
<section>
  <h2>Benchmark</h2>
  <p>coming soon</p>
</section>
 <section>
  <h2>Materials</h2>
  <p>coming soon</p>
  <div class="responsive-content">
    <!-- <a href="https://github.com/crtypist" target="_blank">Github</a> -->
    <!-- <span class="sep"></span> -->
  </div>
</section>
<!-- <section>
  <h2>Authors</h2>
  <a href="https://sdq.github.io" target="_blank"><b>Danqing Shi</b></a><span class="sep"></span>
</section> -->
<section>
    <h2>Cite</h2>

  <!-- <div class="citation-container">
    <div class="citation">Danqing Shi, Xinyue Xu, Fuling Sun, Yang Shi and Nan Cao 2019. Calliope: Automatic Visual Data Story Generation from a Spreadsheet. IEEE Trans. Visualization & Comp. Graphics (Proc. InfoVis), 2021</div>
    <span class="citation-title">Plain Text</span>
  </div> -->

  <div class="citation-container">
    <div class="citation">@article{shi2021crtypist,
      title={CRTypist: Simulating Touchscreen Typing Behavior via Computational Rationality},
      author = {Shi, Danqing and Zhu, Yujun and Jokinen, Jussi and Acharya, Aditya and Putkonen, Aini and Zhai, Shumin and Oulasvirta, Antti},
      journal = {Proceedings of the 2024 CHI conference on human factors in computing systems},
      year={2021},
    }</div>
    <!-- <span class="citation-title">BibteX</span> -->
  </div>
  
  <footer>
 </footer>
</div>
</body>

</html>
